{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f080ed4986927126ebef99025ebe316d",
     "grade": false,
     "grade_id": "cell-c20b837b680f6ecc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# BLU11 - Exercises Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "54ccc9584853cbc1e8b21a4942c07873",
     "grade": false,
     "grade_id": "cell-4322d46a30872977",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import hashlib\n",
    "\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "import scipy as sp\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1182e576c759d4560fbe31873839ae7a",
     "grade": false,
     "grade_id": "cell-ccf01d9e7e51cf46",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# 1 About the Data\n",
    "\n",
    "The data under the `/data/` folder was randomly generated, using the Python `faker` package.\n",
    "\n",
    "It replicates what we would expect from a real-world dataset, corresponding to an RS to recommend movies to users.\n",
    "\n",
    "We have three main files: `/data/users.csv`, `/data/items.csv`, and `/data/ratings.csv`.\n",
    "\n",
    "The files `user.csv` and `items.csv` contain profiles (for users and items, respectively), while ratings have the traditional structure:\n",
    "* UserID, a `sha256` string identifying the user\n",
    "* ItemID, a `sha256` string identifying the item\n",
    "* Rating, with set of possible ratings $S = \\{1, 2, 3, 4, 5\\}$.\n",
    "* Timestamp.\n",
    "\n",
    "User profiles follow the structure: UserID, Username, Name, Sex, Mail and Birthday. \n",
    "\n",
    "Item profiles, in line with the example in the learning materials, contain ItemID and Genre.\n",
    "\n",
    "We build content-based and collaborative filtering pipelines, to provide movie recommendations to users.\n",
    "\n",
    "# 2 Make Ratings\n",
    "\n",
    "At the core of any RS is our base model and, with it, the Ratings matrix.\n",
    "\n",
    "## 1.1 Read Data (graded)\n",
    "\n",
    "We start by creating all the arrays we need to complete the exercise.\n",
    "\n",
    "The data is somewhat different this time because user and item ID are both strings.\n",
    "\n",
    "Although we have all users in the user profiles, we don't readily know what the minimum and maximum values are for items.\n",
    "\n",
    "For users and items, we want the arrays with all possible values, as well as arrays with the values in ratings and the profiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ee3235d18ff5ec5f51542bf14c9fa3f1",
     "grade": false,
     "grade_id": "cell-65abc8147c209707",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def make_data(): \n",
    "    \n",
    "    path_users = os.path.join('data', 'user_profiles.csv')\n",
    "    path_items = os.path.join('data', 'item_profiles.csv')\n",
    "    path_ratings = os.path.join('data', 'ratings.csv')\n",
    "    \n",
    "    # users = read_data(...)\n",
    "    # users_from_ratings = read_data(...)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Sort the users array using ndarray.argsort.\n",
    "    # This will ensure consistency in the order of the rows of the ratings matrix downstream.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # items_from_ratings = read_data(...)\n",
    "    # items_from_profiles = read_data(...)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # ratings = read_data(...)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # genres = read_data(...)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return users, users_from_ratings, items_from_ratings, items_from_profiles, ratings, genres\n",
    "\n",
    "\n",
    "def read_data(path, dtype, column):\n",
    "    # Use np.genfromtxt to build a general function to read the data into arrays with a single\n",
    "    # column. You should ignore headers and use the delimiter ','. \n",
    "    # The return is a rank-1 array.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "68c0bfebbc3ee733dc250cd8ef63745b",
     "grade": true,
     "grade_id": "cell-3cbc6bf19005aa13",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "users, users_from_ratings, items_from_ratings, items_from_profiles, ratings, genres = make_data()\n",
    "\n",
    "\n",
    "assert(users.shape == (1000,))\n",
    "\n",
    "expected_hash = 'f6a9047f7a89eddeba41b154132d54b7fca78311c7fc783245f5f0ae10b9ec0c'\n",
    "assert(hashlib.sha256(users[510]).hexdigest() == expected_hash)\n",
    "\n",
    "assert(users_from_ratings.shape == (5000,))\n",
    "\n",
    "expected_hash = 'af8577a869a89c1cdbf88936bfc83cb4c5049254dc84bc2f5c34cbfbce0415c2'\n",
    "assert(hashlib.sha256(users_from_ratings[3433]).hexdigest() == expected_hash)\n",
    "\n",
    "assert(items_from_ratings.shape == (5000,))\n",
    "\n",
    "expected_hash = 'c5218decaeea9fe00b0cf56498219f6d99dcfc47a9257bc93614f8df19193c82'\n",
    "assert(hashlib.sha256(items_from_ratings[3433]).hexdigest() == expected_hash)\n",
    "\n",
    "assert(ratings.shape == (5000,))\n",
    "\n",
    "expected_hash = 'f0a0278e4372459cca6159cd5e71cfee638302a7b9ca9b05c34181ac0a65ac5d'\n",
    "assert(hashlib.sha256(ratings[3433]).hexdigest() == expected_hash)\n",
    "\n",
    "assert(items_from_profiles.shape == (4900,))\n",
    "\n",
    "expected_hash = '47fe7fb144b5a61d78b87d9000b400010731dbe9ed417486cb1e89bd02b60015'\n",
    "assert(hashlib.sha256(items_from_profiles[3340]).hexdigest() == expected_hash)\n",
    "\n",
    "assert(genres.shape == (4900,))\n",
    "\n",
    "expected_hash = '85f1c8c8e324b6be99b13732edd1770eb0d200d15becbd659cc47ff5e060ac43'\n",
    "assert(hashlib.sha256(genres[3340]).hexdigest() == expected_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8b5d633caa966a2c4435014b823776b7",
     "grade": false,
     "grade_id": "cell-51e746ed8439cdd0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1.2 Make Items (graded)\n",
    "\n",
    "The set of all *known* items $I$ is given by $I_{ratings} \\cup I_{profiles}$, i.e., the union of the items in ratings and item profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "560a7eb0d6e6b39de32e2d9ef5f35600",
     "grade": false,
     "grade_id": "cell-a1366f7067a2ef05",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def make_items(items_from_ratings, items_from_profiles):\n",
    "    \n",
    "    # Use np.concatenate to create a single array with all the items.\n",
    "    # No asserts depend on the order in which you concatenate the arrays.\n",
    "    # items =\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Return a sorted array of unique items, in a rank-1 array.\n",
    "    # Sorting will ensure consistency in the cols of the ratings matrix.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6b19509c3ccf5592212b5f73ccb7470d",
     "grade": true,
     "grade_id": "cell-ef0fa1e229cb86ac",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "items = make_items(items_from_ratings, items_from_profiles)\n",
    "\n",
    "\n",
    "assert(items.shape == (6322,))\n",
    "\n",
    "expected_hash = 'aeeb2b5edeaeb8343409c3809378ec8a271891b2d9e2334f7853047fb445ba5d'\n",
    "assert(hashlib.sha256(items[2863]).hexdigest() == expected_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7830bc3ce3a6f2cdcf8dbff5e43dedc5",
     "grade": false,
     "grade_id": "cell-878e01b13312cca3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1.3 Ratings Matrix (graded)\n",
    "\n",
    "As always, we make the indispensable user-items ratings matrix.\n",
    "\n",
    "We are ready to build it, since we have all the users and all the items we need to account for.\n",
    "\n",
    "We start by building two helper functions, to finding out the row and column indices for each rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "81cbea2339860c6938ae8594c26ce21a",
     "grade": false,
     "grade_id": "cell-57f4a165fcdee93b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = make_ratings_rows(users, users_from_ratings)\n",
    "cols = make_ratings_cols(items, items_from_ratings)\n",
    "\n",
    "\n",
    "assert(rows.shape == cols.shape == (5000,))\n",
    "\n",
    "assert(np.all(rows >= 0))\n",
    "assert(np.all(rows < users.shape[0]))\n",
    "\n",
    "expected_hash = 'ae86f791757dce0e3800c3803b560df4d3825c2cbf254ef5b9f8ea3bdea8fdcc'\n",
    "assert(hashlib.sha256(rows[4457]).hexdigest() == expected_hash)\n",
    "\n",
    "assert(np.all(cols >= 0))\n",
    "assert(np.all(cols < items.shape[0]))\n",
    "\n",
    "expected_hash = 'f5c50ec3895168b69eb366805086712f30164e9ff0b0e8a26e109140efc2da6f'\n",
    "assert(hashlib.sha256(cols[4457]).hexdigest() == expected_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "451e8092812260bd6173c4aacd316f15",
     "grade": false,
     "grade_id": "cell-8f7c16e5990ed218",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Note that we build the matrix differently, because, unlike in previous examples, both the user and item IDs as *strings*.\n",
    "\n",
    "Above, we are building the row and column indices from scratch, instead of using user and item IDs like we did in the learning materials.\n",
    "\n",
    "Also, since we have the complete sets users and items, we can use them to infer the dimensions (number of rows and columns) of the ratings matrix.\n",
    "\n",
    "(Since, given `users` and `items`, we know *how many* users and items there are in our dataset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "16ec6c44a67b6f64e7f296aec7242766",
     "grade": false,
     "grade_id": "cell-33dac9a99978dcbf",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def make_ratings(users, items, users_from_ratings, items_from_ratings, ratings):\n",
    "    \n",
    "    # rows = make_ratings_rows(...)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # cols = make_ratings_cols(...)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # nrows = ...\n",
    "    # ncols = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    shape = (nrows, ncols)\n",
    "    \n",
    "    # data = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Construct a COO sparse matrix.\n",
    "    # coo =\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Return a CSR sparse matrix.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "366c5f4a9d1f2ba6d87cab5c3dc6dae6",
     "grade": true,
     "grade_id": "cell-41def18746aa2cdd",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "R = make_ratings(users, items, users_from_ratings, items_from_ratings, ratings)\n",
    "\n",
    "\n",
    "assert(type(R) == sp.sparse.csr.csr_matrix)\n",
    "assert(R.shape == (1000, 6322))\n",
    "assert(R.count_nonzero() == 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5c380e36826f5a3e8bce797d0d787fd6",
     "grade": false,
     "grade_id": "cell-0085090f12f8d5df",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# 2 Content-based Recommendations\n",
    "\n",
    "Now, we move to the pipeline of content-based filtering recommendations.\n",
    "\n",
    "## 2.1 Make Item Profiles (graded)\n",
    "\n",
    "The first step, as we've seen in the learning materials, is to build the Item Profiles. Shall we?\n",
    "\n",
    "Again, we start with the helper function, to generate the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "02fce582b57000e4bf564fbc0e2278f4",
     "grade": false,
     "grade_id": "cell-15959ad6e7eb16b8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def make_profiles_rows(items, items_from_profiles):\n",
    "    # Combine a list comprehension with np.argwhere to find the index for each \n",
    "    # column in `items_from_profiles` in `items`.\n",
    "    # Remember, to extract the first element of the resulting array use [0, 0].\n",
    "    # rows = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return np.array(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6b8753cae066bb9b9e8968ce25494f6a",
     "grade": false,
     "grade_id": "cell-b8c4425f47c1094b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def make_item_profiles(items, items_from_profiles, genres):\n",
    "    \n",
    "    # Use np.unique to get unique genres, column indicies and value counts,\n",
    "    # that we use in the TF-IDF bit.\n",
    "    # genres_unique, genres_cols, genres_count = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "     \n",
    "    # rows = make_profiles_rows(...)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # cols = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # nrows = ...\n",
    "    # ncols = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    shape = (nrows, ncols)\n",
    "    \n",
    "    # Use NumPy to compute the Inverse Document Frequency (IDF), as we've \n",
    "    # seen in the learning materials.\n",
    "    # idf = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Use idf to give the right weight to each row, as we've seen in the\n",
    "    # materials.\n",
    "    # data = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Construct the sparse matrix as COO.\n",
    "    # coo = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Return a CSR sparse matrix.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9d2e0b588f4b0edead8cbb0091f1eed7",
     "grade": true,
     "grade_id": "cell-f5d2a23c91595e36",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "I = make_item_profiles(items, items_from_profiles, genres)\n",
    "\n",
    "\n",
    "assert(type(I) == sp.sparse.csr.csr_matrix)\n",
    "assert(I.shape == (6322, 16))\n",
    "assert(I.count_nonzero() == 4900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1d532ea37a553856a51ad006746ab1cf",
     "grade": false,
     "grade_id": "cell-ab7c2c82cee04df7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 2.2 Profile Learner (graded)\n",
    "\n",
    "We have successfully built Item Profiles using TF-IDF.\n",
    "\n",
    "Time to test our algebra skills to uncover User Profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9605646c25bbbb5773d0b33977fc0b88",
     "grade": false,
     "grade_id": "cell-6a14f2da36941411",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def profile_learner(R, I):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9d8a674a7e058813a7c296380ed1f9e4",
     "grade": true,
     "grade_id": "cell-9b3a78a6d721ed16",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "U = profile_learner(R, I)\n",
    "\n",
    "\n",
    "assert(type(U) == sp.sparse.csr.csr_matrix)\n",
    "assert(U.shape == (1000, 16))\n",
    "assert(U.count_nonzero() == 2207)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5cd149026aa313fbee47c96088f2b567",
     "grade": false,
     "grade_id": "cell-de4566d9ec7e71f8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 2.3 Content-based Prediction (graded)\n",
    "\n",
    "We generate predictions by computing the similarities between user and item profiles.\n",
    "\n",
    "In this exercise, we don't want our output to be dense, i.e., we must return a sparse matrix. \n",
    "\n",
    "Some functions allow us to pass a `dense_output=False` parameter to ensure the output is sparse if the inputs are sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5e357427fb679b5c474e2bbc0aae013e",
     "grade": false,
     "grade_id": "cell-787ce0c8e22dcd6a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_content_based(U, I):\n",
    "    # Return a sparse matrix with similarities.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8ad0c377611d2515edddcf158f772f38",
     "grade": true,
     "grade_id": "cell-d0474b204c0daaeb",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "R_pred = predict_content_based(U , I)\n",
    "\n",
    "\n",
    "assert(type(R_pred) == sp.sparse.csr.csr_matrix)\n",
    "assert(R_pred.shape == (1000, 6322))\n",
    "assert(R_pred.count_nonzero() == 879378)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3a1c1f00df4c3a56c0ae8e9112371890",
     "grade": false,
     "grade_id": "cell-05ed197925d16cdf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 2.4 Best-item Content-based (graded)\n",
    "\n",
    "We want to exclude previously rated items and recommend the best match to users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c6b6696f07d407bb3dd017041624c423",
     "grade": false,
     "grade_id": "cell-a888079dc9c7f12a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def best_item_content_based(ratings, preds):\n",
    "    \n",
    "    preds_ = preds.copy()\n",
    "    # Convert preds to a LIL sparse matrix, which is more efficient to\n",
    "    # change the sparsity structure.\n",
    "    # preds_ =\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # Replace the predicted ratings for previous rated items with zero.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # Since the changes are done, convert the matrix back to CSR.\n",
    "    # preds_ = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # Return the indeces for the maximum value per row.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5000c995f3cebb9f42d04d9c7cd98bf0",
     "grade": true,
     "grade_id": "cell-ffdbeb0823395fbb",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "L = best_item_content_based(R, R_pred)\n",
    "\n",
    "\n",
    "assert(L.shape == (1000, 1))\n",
    "\n",
    "expected_hash = 'd50dcf8f0079368cc10c2be55ae3fe0c9b30946bda75aacb841cefa0128f7710'\n",
    "assert(hashlib.sha256(L[665][0, 0]).hexdigest() == expected_hash)\n",
    "\n",
    "expected_hash = '608b3f640ca82d78dedccd8d8b7ea423dab7b02f1fa007268a02aaf5969bb9e1'\n",
    "assert(hashlib.sha256(R_pred[665, L[665][0, 0]]).hexdigest() == expected_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "672e166b40a40a61e7a07727de1b7a6c",
     "grade": false,
     "grade_id": "cell-6d7de57dc1ada40c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# 3 Collaborative-filtering\n",
    "\n",
    "Using the Ratings matrix, we can also provide collaborative filtering based recommendations.\n",
    "\n",
    "## 3.1 User Similarities (graded)\n",
    "\n",
    "We compute the user similarities.\n",
    "\n",
    "Again, we want out output, i.e., the similarities matrix, to be sparse. We can do it using the `dense_output` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2b8912b2509c45857174ebbbdc8e7444",
     "grade": false,
     "grade_id": "cell-66e98efae33faba1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def user_similarities(ratings):\n",
    "    # Return a sparce matrix with user-user similarities.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b2ef622f8bfa719f526a33c438ebfab3",
     "grade": true,
     "grade_id": "cell-e930ef59c6826adc",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "U_sim = user_similarities(R)\n",
    "\n",
    "\n",
    "assert(type(U_sim) == sp.sparse.csr.csr_matrix)\n",
    "assert(U_sim.shape == (1000, 1000))\n",
    "assert(U_sim.count_nonzero() == 3513)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5e444a9d7190094909513a57f8233e36",
     "grade": false,
     "grade_id": "cell-bd7109da55e211f5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 3.2 User-based Predictions (graded)\n",
    "\n",
    "Based on the user similarities, we compute predictions as a weighted average of the ratings of other users.\n",
    "\n",
    "(Refer back to the learning materials for the formula.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bab9453f148c7d3095351b7445ea85d2",
     "grade": false,
     "grade_id": "cell-cce81a2541652c0b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_collaborative_filtering_user(ratings, sims):\n",
    "    # preds = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # Replace missing values (result from division by zero, btw) with zero.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # Return the predictions.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "96d44b73ead615670f6724c33d444593",
     "grade": true,
     "grade_id": "cell-e77454cb90250889",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "R_pred_cf_u = predict_collaborative_filtering_user(R, U_sim)\n",
    "\n",
    "\n",
    "assert(R_pred_cf_u.shape == (1000, 6322))\n",
    "assert(R_pred_cf_u[R_pred_cf_u.nonzero()].size == 17691)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0464e645cbf77bbb1f0f6539e9b6698d",
     "grade": false,
     "grade_id": "cell-c6c194502e0b6920",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 3.4 Item Similarities (graded)\n",
    "\n",
    "Alternatively, we can do recommendations based on item-item collaborative filtering.\n",
    "\n",
    "Without surprises, we start by computing item similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "06ca5e9d00e3f59d4e22aa339f927db2",
     "grade": false,
     "grade_id": "cell-81f809744aa16b59",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def item_similarities(ratings):\n",
    "    # Return a sparce matrix with item-item similarities.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4fa9f30b10b93abc1620dff143a554f1",
     "grade": true,
     "grade_id": "cell-c685d66b3588214e",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "I_sim = item_similarities(R)\n",
    "\n",
    "\n",
    "assert(type(I_sim) == sp.sparse.csr.csr_matrix)\n",
    "assert(I_sim.shape == (6322, 6322))\n",
    "assert(I_sim.count_nonzero() == 28667)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "565cacd86aac4a9380d58f0972e4504e",
     "grade": false,
     "grade_id": "cell-025bd071749e9bde",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 3.5 Item-based Predictions (graded)\n",
    "\n",
    "As the last step, we do the predictions, as a weighted average of the ratings of other items.\n",
    "\n",
    "(Formula can be found in the learning materials.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c0aa469fe1724e511085fa722d7f330f",
     "grade": false,
     "grade_id": "cell-84ba689976775cff",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_collaborative_filtering_item(ratings, sims):\n",
    "    # preds = ...\n",
    "    ### BEGIN SOLUION\n",
    "    preds = np.dot(ratings, sims) / np.abs(sims).sum(axis=0)\n",
    "    # Replace missing values with zero.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # Return the predictions.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "295a1ac45a7ceb36d7edc72a864c83cf",
     "grade": true,
     "grade_id": "cell-0afe8cbc286ec6b9",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "R_pred_cf_i = predict_collaborative_filtering_item(R, I_sim)\n",
    "\n",
    "\n",
    "assert(R_pred_cf_i.shape == (1000, 6322))\n",
    "assert(R_pred_cf_i[R_pred_cf_i.nonzero()].size == 17691)\n",
    "assert(R_pred_cf_i.min() >= 0)\n",
    "assert(R_pred_cf_i.max() <= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "861c8b2d61da40adeb58ed592742b558",
     "grade": false,
     "grade_id": "cell-7368280682c88a0b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 3.6 Top-*N* (graded)\n",
    "\n",
    "As for the last step, we want a top-*N* list with collaborative filtering recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f8d6be5dee8531e3604a4b4105bf88a3",
     "grade": false,
     "grade_id": "cell-bf79d6d97d3975b1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def top_n_collaborative_filtering(ratings, preds, n):\n",
    "    # Replace the predicted ratings for previous rated items with zero.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # Return a top-N list by user.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f8ca237e23895eedbd8a8d7b880fe8ed",
     "grade": true,
     "grade_id": "cell-1f951abdbf9d8547",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "top_5_cf_u = top_n_collaborative_filtering(R, R_pred_cf_u, 5)\n",
    "top_5_cf_i = top_n_collaborative_filtering(R, R_pred_cf_i, 5)\n",
    "\n",
    "\n",
    "assert(top_5_cf_u.shape == top_5_cf_i.shape == (1000, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
